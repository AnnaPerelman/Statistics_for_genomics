---
title: 'Lab 1: Gene expression microarrays and differential expression'
author: "Jean-Philippe Fortin"
date: "April 3, 2014"
output: ioslides_presentation
---

## Goals of the lab
Today we will

- get familiar with Affymetrix data
- produce diagnostic plots with basis R commands (Boxplots, densities, MA plots)
- normalize expression data (Quantile normalization, RMA)
- perform a differential analysis with limma (Linear model, Empirical Bayes)
- correct for multiple comparison (Bonferroni, Benjamini & Hochberg )

## Loading packages:
First let's load the **affy** and **affydata** packages from Bioconductor: 
```{r,echo,results='hide', message=FALSE, warning=FALSE}
library(affy)
library(affydata)
```
We will use a dataset containing 4 Affymetrix samples:
```{r}
data(Dilution)
pData(Dilution) #Phenotype information
```

## Raw intensities
The loaded Affymetrix arrays contain two intensities for each probe: one for perfect match **(PM)** and one for mismatch **(MM)**. We will only work with PM intensities.
```{r, message=FALSE, warning=FALSE}
# To obtain the matrix of PM intensities:
raw <- pm(Dilution)
head(raw, n=4)
```
Columns are samples, rows are probes



## Log-Intensities densities
Let's plot the density of the log intensities for each sample:
```{r, echo=FALSE}
library(RColorBrewer) # Optional
palette(brewer.pal(8,"Set1"))
```

```{r}
log.raw <- log2(raw)
plot(density(log.raw[,1]), ylim=c(0,1), xlab="",main="", lwd=3)
for (i in 2:4){lines(density(log.raw[,i]),col=i, lwd=3)}
```

## Log-Intensities Sample 1 vs Sample 2
How do the intensities of Sample 1 compare to the intensities of Sample 2?
```{r}
plot(log.raw[,1], log.raw[,2], pch=20, cex=0.5)
abline(a=0,b=1,col="deepskyblue3", lwd=4) # Draw the blue line
```

## MA plot (Blandâ€“Altman plot)
```{r}
avg  <- (log.raw[,1] + log.raw[,2])/2 # Average
diff <-  log.raw[,1] - log.raw[,2] # Difference
plot(avg, diff, pch=20, cex=0.5)
abline(h=0,col="deepskyblue3", lwd=4)
```

## Lowess curve
http://simplystatistics.org/2014/02/13/loess-explained-in-a-gif/loess/
```{r, eval=FALSE}
lowess.curve <- lowess(x = avg, y = diff, f = 0.05)
#f controls the smoothing span
lines(lowess.curve, col = "deeppink3", lwd = 4)
```

```{r, echo=FALSE}
plot(avg, diff, pch=20, cex=0.5)
abline(h=0,col="deepskyblue3", lwd=4)
lowess.curve <- lowess(x = avg, y = diff, f = 0.05)
lines(lowess.curve, col = "deeppink3", lwd = 4)
```

## Quantile normalization
```{r}
# I usually use the quantile normalization implemented
# in the package preprocessCore
qn <- preprocessCore::normalize.quantiles(log.raw)

plot(density(qn[,1]), ylim=c(0,1), xlab="",main="", lwd=3)
for (i in 2:4){lines(density(qn[,i]),col=i, lwd=3)}
```

## MA plot after quantile normalization
```{r, echo=FALSE}
avg  <- (qn[,1] + qn[,2])/2
diff <-  qn[,1] - qn[,2]
plot(avg, diff, pch=20, cex=0.5)
abline(h=0,col="deepskyblue3", lwd=4)
lowess.curve <- lowess(x = avg, y = diff, f = 0.05)
lines(lowess.curve, col = "deeppink3", lwd = 4)
```
The lowess curve overlaps the 0 line 
## Exercise 1

- Read about loess/lowess normalization. 
- Normalize samples 1 and 2 using the lowess curve that we computed
- How does the MA plot look like after normalization? Does it look better than quantile normalization?


## Scatterplot smoothing

```{r, echo=FALSE}
avg  <- (log.raw[,1] + log.raw[,2])/2
diff <-  log.raw[,1] - log.raw[,2]
lowess.curve <- lowess(x = avg, y = diff, f = 0.05)
```
The function **smoothScatter** can be used to smooth the scatter plot:
```{r, warning=FALSE,message=FALSE}
smoothScatter(avg, diff, ylim = c(-2,2))
lines(lowess.curve, col = "deeppink3", lwd = 3)
abline(h=0, col = "deepskyblue3", lwd=3)
```

## Probe sets
A set of probes targeting the same gene is called a **probeset**. First, let's get the probe name for each row of the PM (or MM) matrix:
```{r}
probe.names <- probeNames(Dilution)
head(probe.names, n=20)
```
The first 16 rows of the PM matrix are probes that belong to the same probeset.


## Gene ids
To obtain the list of probeset ids:
```{r,eval=FALSE}
geneNames(Dilution)
# which is equivalent to
unique(probe.names)
```
To get the PM intensities for a given probeset (here the 20th):
```{r}
x <- pm(Dilution, geneNames(Dilution)[20])
head(x, n=3)
```

## Exercise 2
Can you obtain the median polished intensities for the first probeset ? (look at the class notes to see an example of the median polish algorithm)

## RMA
RMA (Robust Multi-array Average) performs background correction, quantile normalization and applies the median polish algorithm to summarize the probeset intensities. Very simple command: 
```{r}
eset <- rma(Dilution)
nrow(eset)
```

## RMA
The **rma** command returns an ExpressionSet.
```{r}
eset
```

## RMA
Use **exprs** to obtain the summarized expression measures:
```{r}
e <- exprs(eset)
head(e)
dim(e)
```

## Affy diagnostic plots
The **affy** package contains convenient plot commands to draw boxplots, densities and MA plots.
```{r, eval=FALSE}
boxplot(Dilution)
hist(Dilution)
MAplot(Dilution, pairs=TRUE)
MAplot(Dilution, pairs=TRUE, plot.method="smoothScatter")
```

## Boxplots
```{r}
boxplot(Dilution)
```

## MAplots
```{r, warning=FALSE, message=FALSE}
MAplot(Dilution, pairs=TRUE, plot.method="smoothScatter")
```

## Differential analysis with limma
**Goal:** Find genes that have statistically significant different abundances between two (or more) groups. Our dataset only has 4 samples, with no interesting biological treatment group, but we will use it for demonstration purpose. We will use the package **limma**:
```{r, warning=FALSE, message=FALSE}
library(limma)
```
First let's define a comparison group:
```{r}
pd <- pData(Dilution)
groups <- as.factor(pd$liver)
```

## Linear model
For each gene, we want to fit the model $$y_{i} = \beta_0 + \beta_1 x_i$$ where $y_i$ is the expression value for sample $i$, $\beta_0$ is an intercept, $x_i$ is a dummy variable equal to 0 for the first group and 1 for the second group, and $\beta_1$ is the coefficient associated with the change in expression between the two groups. Our goal is to test whether or not $\beta_1 = 0$. 

## DE Analysis
First, we need to construct a design matrix:
```{r}
design.matrix <- model.matrix(~groups)
colnames(design.matrix) <- c("Intercept","Treatment")
design.matrix
```


## Linear model
We can fit the linear models using the **lmFit** function in **limma**. All we need is an expression matrix containing the summarized intensities and the design matrix:
```{r}
fit <- lmFit(object = e, design = design.matrix)
```
**fit** is an object containing the results of the fits. For instance, one can retrieve the coefficients of the linear model with
```{r}
head(fit$coefficients)
```
## Linear model
Note that the **fit** object does not contain any statistical test nor p-value. For each gene, we fitted the model $$y_{i} = \beta_0 + \beta_1 x_i$$ where $y_i$ is the expression value for sample $i$, $\beta_0$ is an intercept, $x_i$ is a dummy variable equal to 0 for the first group and 1 for the second group, and $\beta_1$ is the coefficient associated with the change in expression between the two groups. Our goal is to test whether or not $\beta_1 = 0$. The classical t-statistic is
$$ t = \frac{\hat{\beta_1}}{\frac{s}{\sqrt{n}}}$$

## Classical t-statistic
How can we obtain the t-statistics from the object returned by **lmFit()**?
```{r}
beta <- fit$coefficient[,2]
s <- fit$stdev.unscaled[,2]
n <- 4
t <- (beta*sqrt(n))/s
```
Can you extract the p-value for each gene?

## Empirical Bayes
Computing classical t-statistics for experiments with a small number of arrays is unstable. The Empirical Bayes method implemented in **limma** borrows information across genes to make the analysis more stable. Precisely, the function **eBayes** computes moderated t-statistics by estimating the standard errors using empirical Bayes moderation. 
```{r}
fit2 <- eBayes(fit)
names(fit2)
```

## P-values histogram
Let's create a histogram of the p-values:
```{r}
hist(fit2$p.value[,2])
```

## Volcano plot
A **volcano plot** is used to plot significance (e.g.instance p-value) versus fold-change (e.g. diff. expression coefficient). For our dataset, one can produce a volcano plot as follows:
```{r}
p <- fit2$p.value[,2]
plot(fit2$coefficients[,2], -log2(p), pch=20, cex=0.3)
```

## Volcano plot
**limma** has a command to produce a volcano plot on a fitted object produced by the  **eBayes** command:
```{r}
volcanoplot(fit2, coef=2) 
```

## Volcano plots

- Why did we use the negative logarithm of the p-values instead of the raw p-values?
- The two previous volcano plots look very similar, but are different. Why is that? Type in **?volcanoplot** in the R console to get information about what **volcanoplot** does. 

## Multiple comparison
- The command **p.adjust()** returns adjusted p-values for different methods. (see **?p.adjust**)
- For instance, to correct for Family-Wise Error Rate (FWER), one can use Bonferroni correction:
```{r}
b.pvalues <- p.adjust(p, method = "bonferroni" )
```
- To correct for False Discovery Rate (FDR), one can use the Benjamini-Hochberg correction method:
```{r}
fdr.pvalues <- p.adjust(p, method = "fdr")
summary(fdr.pvalues)
```

## Exercise 3
- Repeat the differential expression analysis, but this time testing for the difference between samples from scanner 1 and samples from scanner 2 (see phenotype information with **pData(Dilution)**). Use RMA to process the data. 
- Produce a histogram of the p-values (computed with **eBayes**)
- Repeat the analysis but this time with data that haven't been background corrected and that are not normalized. Use the median polish algorithm for the probeset summarization. Use the function **expresso()** in the **affy** package to produce the expression matrix. 
- What can you tell about the p-values produced with the RMA-corrected dataset? What can you tell about the p-values produced with the uncorrected data?





